{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import preprocessor as p\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(tweet):\n",
    "    translator = str.maketrans({key: None for key in string.punctuation})\n",
    "    pattern = 'https://t.co/\\w+'\n",
    "    temp = re.sub(pattern, '', tweet)\n",
    "    temp = temp.translate(translator)\n",
    "    return p.clean(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two clusters counts\n",
      "--------------------\n",
      "All Tweets:  Counter({0: 5961, 1: 483})\n",
      "Clinton Clusters:  Counter({0: 3209, 1: 17})\n",
      "Trump Clusters:  Counter({0: 2751, 1: 466})\n",
      "\n",
      "\n",
      "Three clusters counts\n",
      "--------------------\n",
      "All Tweets:  Counter({0: 5166, 1: 786, 2: 492})\n",
      "Clinton Clusters:  Counter({0: 3087, 1: 109, 2: 30})\n",
      "Trump Clusters:  Counter({0: 2079, 1: 676, 2: 462})\n",
      "\n",
      "\n",
      "Four clusters counts\n",
      "--------------------\n",
      "All Tweets:  Counter({0: 3159, 1: 1554, 3: 1240, 2: 491})\n",
      "Clinton Clusters:  Counter({0: 1875, 1: 920, 3: 411, 2: 20})\n",
      "Trump Clusters:  Counter({0: 1284, 3: 828, 1: 634, 2: 471})\n",
      "\n",
      "\n",
      "Five clusters counts\n",
      "--------------------\n",
      "All Tweets:  Counter({0: 3538, 2: 1179, 3: 1078, 1: 475, 4: 174})\n",
      "Clinton Clusters:  Counter({0: 1667, 3: 775, 2: 708, 1: 76})\n",
      "Trump Clusters:  Counter({0: 1870, 2: 471, 1: 399, 3: 303, 4: 174})\n",
      "\n",
      "\n",
      "6 clusters counts\n",
      "--------------------\n",
      "All Tweets:  Counter({1: 2954, 0: 1706, 3: 731, 5: 469, 4: 449, 2: 135})\n",
      "Clinton Clusters:  Counter({1: 1648, 0: 633, 3: 589, 4: 311, 5: 31, 2: 14})\n",
      "Trump Clusters:  Counter({1: 1306, 0: 1072, 5: 438, 3: 142, 4: 138, 2: 121})\n",
      "\n",
      "\n",
      "Eight clusters counts\n",
      "--------------------\n",
      "All Tweets:  Counter({6: 2369, 5: 918, 1: 898, 4: 807, 2: 750, 0: 424, 7: 144, 3: 134})\n",
      "Clinton Clusters:  Counter({6: 1049, 4: 632, 2: 625, 1: 505, 5: 345, 0: 57, 3: 13})\n",
      "Trump Clusters:  Counter({6: 1319, 5: 573, 1: 393, 0: 367, 4: 175, 7: 144, 2: 125, 3: 121})\n",
      "\n",
      "\n",
      "12 clusters counts\n",
      "--------------------\n",
      "All Tweets:  Counter({13: 2719, 2: 1578, 8: 891, 1: 466, 16: 340, 19: 317, 3: 119, 12: 2, 0: 1, 4: 1, 5: 1, 6: 1, 7: 1, 9: 1, 10: 1, 11: 1, 14: 1, 15: 1, 17: 1, 18: 1})\n",
      "Clinton Clusters:  Counter({13: 1141, 2: 963, 8: 667, 16: 249, 1: 191, 19: 8, 4: 1, 6: 1, 7: 1, 10: 1, 14: 1, 15: 1, 18: 1})\n",
      "Trump Clusters:  Counter({13: 1577, 2: 615, 19: 309, 1: 275, 8: 224, 3: 119, 16: 91, 12: 2, 0: 1, 5: 1, 9: 1, 11: 1, 17: 1})\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "training_data = pd.read_csv('datasets/tweets.csv', delimiter=',')\n",
    "\n",
    "clinton_data = training_data[training_data.handle == \"HillaryClinton\"][\"text\"].as_matrix()\n",
    "trump_data = training_data[training_data.handle == \"realDonaldTrump\"][\"text\"].as_matrix()\n",
    "\n",
    "clinton_data = np.array(list(map(clean,clinton_data.tolist())))\n",
    "trump_data = np.array(list(map(clean,trump_data.tolist())))\n",
    "\n",
    "all_data = np.concatenate((clinton_data,trump_data), axis=0)\n",
    "all_data = list(map(clean, all_data.tolist()))\n",
    "all_data = np.array(all_data)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(all_data)\n",
    "\n",
    "\n",
    "km2 = MiniBatchKMeans(reassignment_ratio=.01, n_clusters=2, n_init=300, max_iter=3000).fit(X)\n",
    "predictions2 = km2.predict(X)\n",
    "# look at both cluster counts\n",
    "count2 = Counter(predictions2.tolist())\n",
    "# only hillary tweet clusters\n",
    "count2_clinton = Counter(predictions2.tolist()[:3226])\n",
    "# only trump clusters\n",
    "count2_trump = Counter(predictions2.tolist()[3227:])\n",
    "print(\"Two clusters counts\")\n",
    "print(\"--------------------\")\n",
    "print(\"All Tweets: \", count2)\n",
    "print(\"Clinton Clusters: \", count2_clinton)\n",
    "print(\"Trump Clusters: \", count2_trump)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "km3 = MiniBatchKMeans(reassignment_ratio=.03, n_clusters=3, n_init=2000, max_iter=4000).fit(X)\n",
    "predictions3 = km3.predict(X)\n",
    "count3 = Counter(predictions3.tolist())\n",
    "count3_clinton = Counter(predictions3.tolist()[:3226])\n",
    "count3_trump = Counter(predictions3.tolist()[3227:])\n",
    "print(\"Three clusters counts\")\n",
    "print(\"--------------------\")\n",
    "print(\"All Tweets: \", count3)\n",
    "print(\"Clinton Clusters: \", count3_clinton)\n",
    "print(\"Trump Clusters: \", count3_trump)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "km4 = MiniBatchKMeans(reassignment_ratio=.03, n_clusters=4, n_init=2000, max_iter=4000).fit(X)\n",
    "predictions4 = km4.predict(X)\n",
    "count4 = Counter(predictions4.tolist())\n",
    "count4_clinton = Counter(predictions4.tolist()[:3226])\n",
    "count4_trump = Counter(predictions4.tolist()[3227:])\n",
    "print(\"Four clusters counts\")\n",
    "print(\"--------------------\")\n",
    "print(\"All Tweets: \", count4)\n",
    "print(\"Clinton Clusters: \", count4_clinton)\n",
    "print(\"Trump Clusters: \", count4_trump)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "km5 = MiniBatchKMeans(reassignment_ratio=.05, n_clusters=5, n_init=2000, max_iter=4000).fit(X)\n",
    "predictions5 = km5.predict(X)\n",
    "count5 = Counter(predictions5.tolist())\n",
    "count5_clinton = Counter(predictions5.tolist()[:3226])\n",
    "count5_trump = Counter(predictions5.tolist()[3227:])\n",
    "print(\"Five clusters counts\")\n",
    "print(\"--------------------\")\n",
    "print(\"All Tweets: \", count5)\n",
    "print(\"Clinton Clusters: \", count5_clinton)\n",
    "print(\"Trump Clusters: \", count5_trump)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "km6 = MiniBatchKMeans(reassignment_ratio=.05, n_clusters=6, n_init=2000, max_iter=4000).fit(X)\n",
    "predictions6 = km6.predict(X)\n",
    "count6 = Counter(predictions6.tolist())\n",
    "count6_clinton = Counter(predictions6.tolist()[:3226])\n",
    "count6_trump = Counter(predictions6.tolist()[3227:])\n",
    "print(\"6 clusters counts\")\n",
    "print(\"--------------------\")\n",
    "print(\"All Tweets: \", count6)\n",
    "print(\"Clinton Clusters: \", count6_clinton)\n",
    "print(\"Trump Clusters: \", count6_trump)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "km8 = MiniBatchKMeans(reassignment_ratio=.05, n_clusters=8, n_init=2000, max_iter=4000).fit(X)\n",
    "predictions8 = km8.predict(X)\n",
    "count8 = Counter(predictions8.tolist())\n",
    "count8_clinton = Counter(predictions8.tolist()[:3226])\n",
    "count8_trump = Counter(predictions8.tolist()[3227:])\n",
    "print(\"Eight clusters counts\")\n",
    "print(\"--------------------\")\n",
    "print(\"All Tweets: \", count8)\n",
    "print(\"Clinton Clusters: \", count8_clinton)\n",
    "print(\"Trump Clusters: \", count8_trump)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "km12 = MiniBatchKMeans(reassignment_ratio=.05, n_clusters=12, n_init=2000, max_iter=4000).fit(X)\n",
    "predictions12 = km12.predict(X)\n",
    "count12 = Counter(predictions12.tolist())\n",
    "count12_clinton = Counter(predictions12.tolist()[:3226])\n",
    "count12_trump = Counter(predictions12.tolist()[3227:])\n",
    "print(\"12 clusters counts\")\n",
    "print(\"--------------------\")\n",
    "print(\"All Tweets: \", count12)\n",
    "print(\"Clinton Clusters: \", count12_clinton)\n",
    "print(\"Trump Clusters: \", count12_trump)\n",
    "print(\"\")\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
